"""Utilities for comparing MEGqc metrics across multiple samples.

This script expects the TSV files generated by the MEGqc pipeline for each
sample and produces a set of violin plots, a linear regression table and
scatter plots comparing the samples.

Example
-------
Assuming you have the metrics exported for two datasets, run::

    python -m meg_qc.calculation.between_sample_analysis \
        --tsv sample1/group_metrics.tsv sample2/group_metrics.tsv \
        --names sample1 sample2 \
        --output-dir results

All figures and the regression table will be stored in ``results``.
"""
import argparse
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from scipy import stats
import statsmodels.api as sm

LABEL_MAP = {
    "GQI": "GQI",
    "GQI_std_pct": "STD noise",
    "GQI_ptp_pct": "PtP noise",
    "GQI_ecg_pct": "ECG noise",
    "GQI_eog_pct": "EOG noise",
    "GQI_muscle_pct": "Muscle noise",
    "GQI_psd_noise_pct": "PSD noise",
    "GQI_penalty_ch": "Variability penalty",
    "GQI_penalty_corr": "Correlational penalty",
    "GQI_penalty_mus": "Muscle penalty",
    "GQI_penalty_psd": "PSD penalty",
}


def _get_star(p):
    """Return asterisks representing the p-value significance."""
    if p < 0.001:
        return "***"
    if p < 0.01:
        return "**"
    if p < 0.05:
        return "*"
    return ""


def _load_tables(paths):
    """Load TSV tables into pandas DataFrames."""
    tables = []
    for p in paths:
        df = pd.read_csv(p, sep="\t")
        tables.append(df)
    return tables


def _make_violin(data, names, title, ylabel, out_png):
    """Create violin plot comparing samples."""
    violin_data = [d.dropna() for d in data]
    palette = cm.get_cmap("tab10", len(violin_data))
    plt.figure(figsize=(10, 6))
    parts = plt.violinplot(violin_data, showmeans=True, showextrema=True,
                            showmedians=False, widths=0.8)
    for i, pc in enumerate(parts["bodies"]):
        pc.set_facecolor(palette(i))
        pc.set_edgecolor("black")
        pc.set_alpha(0.5)
    parts["cmeans"].set_linewidth(2)
    parts["cmeans"].set_color("black")
    parts["cbars"].set_color("black")
    for i, y in enumerate(violin_data, start=1):
        x = np.random.normal(i, 0.05, size=len(y))
        plt.scatter(x, y, s=20, alpha=0.4, edgecolor="black", linewidth=0.5,
                    facecolor=palette(i - 1))
    plt.xticks(range(1, len(names) + 1), names, rotation=0, ha="center", fontsize=10)
    plt.ylabel(ylabel)
    plt.title(title)
    plt.tight_layout()
    plt.savefig(out_png, dpi=300)
    plt.close()


def _cumulative_plot(tables, metrics, names, out_png, out_tsv=None):
    """Create a cumulative violin plot of several metrics for each sample.

    If ``out_tsv`` is provided, pairwise t-test results will be written
    to that path.
    """
    n_samples = len(names)
    fig, ax = plt.subplots(figsize=(12, 6))
    palette = cm.get_cmap("tab10", len(metrics))

    positions = []
    labels = []
    results = []
    for j, metric in enumerate(metrics):
        metric_values = []
        for i, name in enumerate(names):
            data = tables[i][metric].dropna()
            pos = j * n_samples + i + 1
            parts = ax.violinplot(
                [data],
                positions=[pos],
                showmeans=True,
                showextrema=True,
                showmedians=False,
                widths=0.8,
            )
            color = palette(j)
            for pc in parts["bodies"]:
                pc.set_facecolor(color)
                pc.set_edgecolor("black")
                pc.set_alpha(0.5)
            parts["cmeans"].set_linewidth(2)
            parts["cmeans"].set_color("black")
            parts["cbars"].set_color("black")
            x = np.random.normal(pos, 0.05, size=len(data))
            ax.scatter(
                x,
                data,
                s=20,
                alpha=0.4,
                edgecolor="black",
                linewidth=0.5,
                facecolor=color,
            )
            metric_values.append(data)
            positions.append(pos)
            labels.append(name)

        # add significance annotations
        y_range = ax.get_ylim()
        y_offset = (y_range[1] - y_range[0]) * 0.05
        offset_count = 0
        for a in range(n_samples):
            for b in range(a + 1, n_samples):
                stat, p = stats.ttest_ind(
                    metric_values[a],
                    metric_values[b],
                    equal_var=False,
                )
                star = _get_star(p)
                results.append(
                    {
                        "metric": metric,
                        "sample1": names[a],
                        "sample2": names[b],
                        "t_stat": stat,
                        "p": p,
                        "asterisk": star,
                    }
                )
                if not star:
                    continue
                x1 = j * n_samples + a + 1
                x2 = j * n_samples + b + 1
                y = max(metric_values[a].max(), metric_values[b].max()) + (
                    offset_count + 1
                ) * y_offset
                ax.plot(
                    [x1, x1, x2, x2],
                    [y, y + y_offset / 2, y + y_offset / 2, y],
                    color="black",
                )
                ax.text((x1 + x2) / 2, y + y_offset / 2, star, ha="center", va="bottom")
                offset_count += 1

    ax.set_xticks(positions)
    ax.set_xticklabels(labels, rotation=0, ha="center", fontsize=9)
    ax.set_ylabel("Percentage of Quality and Noisy Channels")
    ax.set_title("Metrics across samples")

    secax = ax.secondary_xaxis(
        "bottom",
        functions=(lambda x: x, lambda x: x),
    )
    centers = [j * n_samples + (n_samples + 1) / 2 for j in range(len(metrics))]
    secax.set_xticks(centers)
    secax.set_xticklabels([LABEL_MAP.get(m, m) for m in metrics], fontsize=10, fontweight="bold")
    secax.tick_params(pad=20)

    fig.tight_layout()
    fig.savefig(out_png, dpi=300)
    if out_tsv is not None:
        pd.DataFrame(results).to_csv(out_tsv, sep="\t", index=False)
    plt.close(fig)


def _perform_regression(df, metrics, out_tsv):
    """Run linear regression and save results."""
    X = df[metrics].copy()
    # add all pairwise interactions
    for i, m1 in enumerate(metrics):
        for m2 in metrics[i + 1:]:
            X[f"{m1}:{m2}"] = df[m1] * df[m2]
    X = sm.add_constant(X)
    model = sm.OLS(df["GQI"], X, missing="drop").fit()
    res_df = pd.DataFrame({
        "variable": model.params.index,
        "coef": model.params.values,
        "std_err": model.bse.values,
        "t": model.tvalues.values,
        "p": model.pvalues.values,
    })
    res_df["asterisk"] = res_df["p"].apply(_get_star)
    sig_df = res_df[res_df["asterisk"] != ""].copy()
    sig_df.to_csv(out_tsv, sep="\t", index=False)
    return model, sig_df


def _scatter_plots(df, model, metrics, out_dir, sig_vars):
    """Create scatter plots for significant terms from the regression."""

    for var in sig_vars:
        if var == "const":
            continue
        if ":" in var:
            m1, m2 = var.split(":")
            if m1 not in df.columns or m2 not in df.columns:
                continue
            fig = plt.figure(figsize=(8, 6))
            ax = fig.add_subplot(111, projection="3d")
            ax.scatter(df[m1], df[m2], df["GQI"], alpha=0.6, edgecolor="black")

            x = np.linspace(df[m1].min(), df[m1].max(), 20)
            y = np.linspace(df[m2].min(), df[m2].max(), 20)
            xx, yy = np.meshgrid(x, y)
            pred_data = {}
            for param in model.params.index:
                if param == "const":
                    continue
                if param == m1:
                    pred_data[param] = xx
                elif param == m2:
                    pred_data[param] = yy
                elif param == var:
                    pred_data[param] = xx * yy
                elif ":" in param:
                    p1, p2 = param.split(":")
                    val1 = xx if p1 == m1 else yy if p1 == m2 else df[p1].mean()
                    val2 = xx if p2 == m1 else yy if p2 == m2 else df[p2].mean()
                    pred_data[param] = val1 * val2
                else:
                    pred_data[param] = df[param].mean()
            grid_df = pd.DataFrame({k: v.ravel() for k, v in pred_data.items()})
            grid_df = sm.add_constant(grid_df, has_constant="add")
            preds = model.predict(grid_df).values.reshape(xx.shape)
            ax.plot_surface(xx, yy, preds, color="red", alpha=0.3)

            beta = model.params.get(var, float("nan"))
            pval = model.pvalues.get(var, float("nan"))
            fig.text(0.05, 0.95, f"Î²={beta:.3f}, p={pval:.3g}", ha="left", va="top")
            ax.set_xlabel(LABEL_MAP.get(m1, m1))
            ax.set_ylabel(LABEL_MAP.get(m2, m2))
            ax.set_zlabel("GQI")
            ax.set_title(
                f"GQI vs {LABEL_MAP.get(m1, m1)} and {LABEL_MAP.get(m2, m2)}"
            )
            fig.tight_layout()
            fig.savefig(os.path.join(out_dir, f"{m1}_{m2}_interaction_scatter.png"), dpi=300)
            plt.close(fig)
        else:
            m = var
            if m not in df.columns:
                continue
            plt.figure(figsize=(8, 6))
            plt.scatter(df[m], df["GQI"], alpha=0.6, edgecolor="black")

            x = np.linspace(df[m].min(), df[m].max(), 100)
            pred_data = {}
            for param in model.params.index:
                if param == "const":
                    continue
                if param == m:
                    pred_data[param] = x
                elif ":" in param:
                    m1, m2 = param.split(":")
                    if m1 == m:
                        val1 = x
                        val2 = df[m2].mean()
                    elif m2 == m:
                        val1 = df[m1].mean()
                        val2 = x
                    else:
                        val1 = df[m1].mean()
                        val2 = df[m2].mean()
                    pred_data[param] = val1 * val2
                else:
                    pred_data[param] = df[param].mean()
            X_new = pd.DataFrame(pred_data)
            X_new = sm.add_constant(X_new, has_constant="add")
            preds = model.get_prediction(X_new).summary_frame(alpha=0.05)
            plt.plot(x, preds["mean"], color="red")
            plt.fill_between(
                x,
                preds["mean_ci_lower"],
                preds["mean_ci_upper"],
                color="red",
                alpha=0.2,
            )
            beta = model.params.get(m, float("nan"))
            pval = model.pvalues.get(m, float("nan"))
            plt.annotate(
                f"Î²={beta:.3f}, p={pval:.3g}",
                xy=(0.05, 0.95),
                xycoords="axes fraction",
                ha="left",
                va="top",
            )
            plt.xlabel(LABEL_MAP.get(m, m))
            plt.ylabel("GQI")
            plt.title(f"GQI vs {LABEL_MAP.get(m, m)}")
            plt.tight_layout()
            plt.savefig(os.path.join(out_dir, f"{m}_scatter.png"), dpi=300)
            plt.close()


def main():
    parser = argparse.ArgumentParser(description="Between sample analysis")
    parser.add_argument("--tsv", nargs="+", required=True,
                        help="Paths to group metrics TSV files")
    parser.add_argument("--names", nargs="+", required=True,
                        help="Sample names corresponding to TSV files")
    parser.add_argument("--output-dir", required=True, help="Directory for outputs")
    args = parser.parse_args()

    if len(args.tsv) != len(args.names):
        raise ValueError("Number of TSV files must match number of names")

    os.makedirs(args.output_dir, exist_ok=True)
    cumulative_dir = os.path.join(args.output_dir, "cummlative_violin_plot")
    separated_dir = os.path.join(args.output_dir, "separated_violin_plot")
    regression_dir = os.path.join(args.output_dir, "regression")
    os.makedirs(cumulative_dir, exist_ok=True)
    os.makedirs(separated_dir, exist_ok=True)
    os.makedirs(regression_dir, exist_ok=True)

    tables = _load_tables(args.tsv)
    metrics = [
        "GQI_std_pct",
        "GQI_ptp_pct",
        "GQI_ecg_pct",
        "GQI_eog_pct",
        "GQI_muscle_pct",
        "GQI_psd_noise_pct",
    ]

    # Violin plot for GQI
    gqi_data = [tbl["GQI"] for tbl in tables]
    _make_violin(
        gqi_data,
        args.names,
        "Global Quality Index",
        LABEL_MAP["GQI"],
        os.path.join(separated_dir, "GQI_violin.png"),
    )

    # Metric specific violin plots
    for m in metrics:
        metric_data = [t[m] for t in tables if m in t.columns]
        if not metric_data:
            continue
        _make_violin(
            metric_data,
            args.names,
            LABEL_MAP.get(m, m),
            LABEL_MAP.get(m, m),
            os.path.join(separated_dir, f"{m}_violin.png"),
        )

    _cumulative_plot(
        tables,
        ["GQI", *metrics],
        args.names,
        os.path.join(cumulative_dir, "cumulative_metrics.png"),
        os.path.join(cumulative_dir, "t_test_results.tsv"),
    )

    # Combine all data for regression
    df_all = []
    for name, tbl in zip(args.names, tables):
        temp = tbl.copy()
        temp["sample"] = name
        df_all.append(temp)
    df_all = pd.concat(df_all, ignore_index=True)

    reg_model, sig_df = _perform_regression(
        df_all, metrics, os.path.join(regression_dir, "linear_regression_results.tsv")
    )

    sig_vars = set(sig_df["variable"])
    _scatter_plots(df_all, reg_model, metrics, regression_dir, sig_vars)


if __name__ == "__main__":
    main()
